
Scholarly Article:

https://www.sciencedirect.com/science/article/pii/S2212041617301559?casa_token=1TudC9YygHcAAAAA:KoR3h73zpIZMc03E5LyUIeLzHbbYcLx8V7GwMhKUGCOB_qLtqIvL3QmNpM11MhL9EvuTMsZs

Computation Method: Image Recognition (Machine Learning)
Cultural Data: Social Media Photographs

In the article, researchers discussed wanting to use photos from social media to understand how people appreciate nature (like through recreational activities) in Singapore. But analyzing these photos manually would take too long, so they used machine learning to automate the process. They gathered over 20,000 photos from Flickr, a social media site where users share photos. These photos were tagged with location information (geo-tagged), so they knew where each photo was taken in Singapore. They used a machine learning tool called Google Cloud Vision to analyze each photo. This tool automatically identified what was in the photos and added keywords (like "plant," "animal," "food," etc.) to describe them. They looked at where the nature photos (like of plants and animals) were most commonly taken. They found that photos were concentrated around certain places in Singapore, like parks and nature reserves. They created a model to understand what factors influenced where nature photos were taken. They looked at things like, how close the photo was to popular tourist spots and how much greenery (like parks or forests) was nearby. This automated method can be used to quickly map and study how people interact with nature, helping urban planners understand which areas people value for nature activities. 
What I found interesting was how the researchers were able to leverage automated content analysis of social media photos, allowing researchers to analyze vast amounts of data (over 20,000 photos in this case) much more quickly and efficiently.  Just as the researchers used Google Cloud Vision to analyze social media photos, we can use similar image recognition tools to automatically analyze screenshots or images from the Flash dress-up games. The image recognition tool can identify elements like skin tone, clothing, hair styles, and other visual features in the characters. By processing the images of characters in the Flash games, we can track how different features appear in the games before and after 2011.

4. 
For our group project, we are thinking of using image recognition and machine learning (ML) to extract skin colors from Adobe Flash game screenshots. This method will allow us to analyze the diversity of characters, specifically how skin tones are represented, in dress-up games over time.
We chose this method because it enables us to automatically process a large number of game screenshots, saving significant time compared to manual analysis. By leveraging image recognition tools and pre-trained ML models, we can efficiently identify and classify different skin tones in the characters. This will help us track how the representation of diverse skin tones has evolved before and after 2011 in the games.

